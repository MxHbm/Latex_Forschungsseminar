\chapter{Motivation for Feasibility Prediction}
\label{sec:motivation_feasibility_prediction}
This section explores how \gls{ML} algorithms can enhance \gls{CLP} solution strategies,
highlighting both benefits and limitations. Two papers will be
analyzed, which use predictive methods to accelerate the computation time. Before that,
a short introduction to classifiers will be conducted. It is important to note that
several machine learning approaches address the \textit{on-line} \gls{BPP}, where the optimal placement
of individual items, arriving sequentially, must be determined.\footcite[cf.][p. 1]{ali_-line_2022}
Since this work focuses on the \textit{off-line} \gls{BPP}, where a placement for all items is determined
simultaneously, on-line approaches are not further considered. The emphasis is placed primarily
on \gls{ML}-based classifiers. These are supervised \gls{ML} algorithms predicting the
value of a categorical or binary output column, called label, based on the
values of other columns, called features. Classifiers learn from a labeled dataset,
where the correct output values are known in advance, and then use this knowledge to
make predictions on new, unseen data. The accuracy can be evaluated afterwards by comparing
the predicted labels with the actual labels. \footcite[cf.][]{kotsiantis_supervised_2007}
An exemplary train dataset is shown in Table~\ref{tab:classifier_label_data}.

\input{tables/label_classifier}

A classifier can be implemented using various \gls{ML} models such as \gls{LR},
\gls{ANN}, support vector machine, or others. However, the most crucial aspect of any
\gls{ML} model is the selection of data, particularly the choice of features and
the size of the training set, since many models can be easily preselected from available
libraries. The model attempts to learn correlations between the provided features
and the corresponding labels. If the features are poorly chosen, the model may fail
to capture the underlying patterns in the data. Additionally, if the training set
is too small, the model might not generalize well, ultimately lacking the ability
to accurately predict unseen data. Furthermore, it needs to be noted, that available
\gls{ML} models are not by nature superior to others, but can significantly outperform
others on specific application problem \footcite[cf.][pp. 250, 264]{kotsiantis_supervised_2007}.
The usage of classifiers is promising to complement exisiting algorithms, as shown in the following.

\subsubsection{Feasibility Classifier of the \cgls{2L-CVRP}}
A practical application of the \gls{CLP} is the integration in the \gls{VRP}, where
a number of customers need to be served with a set of items by a fleet of vehicles that have
to start from a depot and return. The goal is to minimize the total distance driven
by the vehicles. When considering multidimensional items, the NP-hard problem itself,
increases in complexity, as every tour is representing a \gls{CLP} itself. \footcite[cf.][pp. 1--2]{tamke_branch-and-cut_2024}
\citeauthor*{zhang_learning-based_2022} used a binary classifier to predict the feasibility of the
loading of single tours to reduce the overall computation time in their exact branch-and-price
algorithm. As many single tours need to be evaluated, the \gls{ANN} model reduced the need
to control the solutions only when they are discarded or accepted. The default approach would be to
determine feasibility by applying a exact feasibility checker, such as a \gls{CP} or \gls{MIP} model.
The classifier performed well and had an accuracy of at most $94.1\%$. However, some simplifications were made,
they allowed no stacking of items tackling the \cgls{2L-CVRP} and no further constraints,
as unloading sequence, rotation or stability (see Chapter~\ref{sec:clp_definition}) were considered.
The classifier was trained with a dataset of $50,000$ tours obtained by the underlying column generation
algorithm containing 17 hand-crafted features capturing geometric
and spatial characteristics of the packing problem. These include the ratio of the total item area
to the container floor area, as well as the mean, standard deviation, minimum, and maximum of
the following four indicators:
\begin{itemize}
    \item[1.] The ratio of item width to item height.
    \item[2.] The ratio of item width to the container width.
    \item[3.] The ratio of item height to the container height.
    \item[4.] The ratio of each itemâ€™s area to the total container area.
\end{itemize}
The \gls{ANN} model was trained in many epochs
using the \textit{Mini-Batch Gradient Descent Algorithm}. By integrating the classifier into the
exisiting branch-and-price algorithm, the CPU time was reduced by $54.12\%$ and the frequency of
calling the exact feasibility checker by $87.22\%$ on average. However, the objective values are not significantly
lower and the authors assume that the prediction accuracy does not influence the solution quality
to a high extent, as the objectve values obtained by the \gls{LR} model are similar. \footcite[cf.][pp. 4, 9--15]{zhang_learning-based_2022}

\subsubsection{Pallet Size Classifier for the \gls{PLP}}
Another use case for \gls{ML} in packing problems is presented by \citeauthor*{aylak_application_2021},
who focus on selecting the optimal pallet size in the context of the \gls{PLP}. Here a number of fixed items
need to be placed on paletts with fixed weight, length and height dimensions, optimizing the volume utilization
generating subsequently stability and minimizing the number of pallets needed. Based on real-life data
three candidate pallet sizes were considered and the best packing pattern must be found for each packing
configuration defined by the number of boxes and their uniform size. Therefore, multiple packing heuristics were applied to
generate feasible packing patterns and identify the best-performing. These are used as labels for several
\gls{ML} models, which were trained to predict the optimal pallet size based on four input features: the box
dimensions \{x,y,z\} and the demand quantity. Compared to the purely heuristic approach, the classifier-based
determination achieved a volume utilization improvement of $6.7\%$ and significantly reduced computation time.
However, the study did not consider additional constraints such as weight limits, stacking rules, or stability.\footcite[cf.][pp. 12--14]{aylak_application_2021}

\parbreak

These two examples demonstrate that classifiers can be successfully integrated into existing \gls{CLP}
algorithms to reduce computation time and overall complexity, provided the classifier is well trained.
However, training such a model is often time-consuming, and the practicality of both training and
integrating a classifier must be carefully evaluated on a case-by-case basis.
In the two examples presented, the number of constraints was relatively small, allowing the classifier
to be trained with a limited set of features. When more complex constraints are introduced, such as
\gls{LIFO} unloading rules or item fragility, the construction of numerical features that accurately
represent these constraints becomes significantly more challenging.
Moreover, results achieved by simple classifiers often lack practical relevance, since real-world
scenarios, such as loading large containers or trucks, inevitably involve multiple constraints that
must be taken into account. Therefore, the development of a classifier is not only demanding but also
requires careful consideration to ensure a favorable cost-benefit ratio.
A particularly promising and practically relevant application is the prediction of the feasibility of single tours for the
\gls{3L-CVRP} with constraints, an extension of the \gls{2L-CVRP} example discussed earlier. In the
\gls{3L-CVRP}, a large number of routes must be evaluated to identify those that minimize the total
distance traveled by all vehicles. While the packing of requested items does not need to satisfy
optimization criteria, it must still be feasible under the given \gls{CLP} constraints.\footcite[cf.][]{tamke_branch-and-cut_2024}
As discussed in Chapter~\ref{sec:classical_solution_approaches}, the verification of
packing feasibility for each individual route is computationally expensive.
Here, classifiers can significantly boost performance of existing exact algorithms by rapidly predicting the feasibility of the route. The
exact packing solution is then only computed for the final solution candidates or before an infeasible classified solution
is discarded to avoid incorrect eliminations, as presented above.
To facilitate this approach, a comparison of various published \gls{3L-CVRP} datasets will be conducted
to compare and identify the most appropriate dataset for training a binary feasibility classifier.